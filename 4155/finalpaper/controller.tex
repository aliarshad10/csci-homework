\section{Controller Architecture}
\label{section::controller}

The overall solution was divided into smaller tasks, which would work well in parallel. The aim was to have all of the processes running in parallel and then combine them together in order to decide which action to take given the robots current perceived location. We also included past data and the robotâ€™s history through a Proportional-Integral-Derivative (PID) controller. In the final implementation, the sub processes ran in a pseudo parallel manor. The processes ran in sequence, but independently of each other.  The results were all taken into account as if they had been run in parallel. This decision was made due to time constraints and not knowing the technical nuances of python multiprocessing. A purely parallel implementation would likely be faster. At the beginning of each step, the robot locates itself which requires grabbing several frames from the webcam and discarding the first few because the camera has autofocus and colour filters that cannot be turned off. If the OpenCV components could be run in parallel, the location and orientation of the robot could be queried at any time without waiting for the camera to re adjust and grabbing unnecessary frames.
